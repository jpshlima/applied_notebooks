{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us make the imports for the entire code\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import time\n",
    "# Enable to start counting processing time\n",
    "# start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here we read and organize CSV data\n",
    "\n",
    "t2 = pd.read_csv('t2_OkumuraHata_Modificado', delimiter='\\t')\n",
    "t3 = pd.read_csv('t3_OkumuraHata_Modificado', delimiter='\\t')\n",
    "min_download = pd.read_csv('file1.csv', delimiter=',')\n",
    "\n",
    "# Guarantee that we utilize only seeds present in both datasets\n",
    "t2 = t2[t2.nRun.isin(t3.nRun)]\n",
    "t3 = t3[t3.nRun.isin(t2.nRun)]\n",
    "t2 = t2.reset_index(drop=True)\n",
    "t3 = t3.reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Combining datasets\n",
    "data = t2\n",
    "data = data.drop(['targetCellId', 'downloadTime', 'rxBytes'], axis=1)\n",
    "data['downloadTimeT2'] = t2.downloadTime\n",
    "data['downloadTimeT3'] = t3.downloadTime\n",
    "data['downloadTime'] = min_download.downloadTimeT2\n",
    "data['rxBytesT2'] = t2.rxBytes\n",
    "data['rxBytesT3'] = t3.rxBytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre-processing\n",
    "\n",
    "\n",
    "# Sets data as inputs and labels\n",
    "previsores = data[['rsrp1','rsrq1','rsrp2','rsrq2','rsrp3','rsrq3','previousrsrp1','previousrsrq1','previousrsrp2','previousrsrq2','previousrsrp3','previousrsrq3']]\n",
    "previsores = previsores.values\n",
    "label = data[['downloadTime']] \n",
    "label = label.values\n",
    "\n",
    "# Scaling data\n",
    "scaler_x = MinMaxScaler(feature_range=(0, 1))\n",
    "previsores = scaler_x.fit_transform(previsores)\n",
    "scaler_y = MinMaxScaler(feature_range=(0, 1))\n",
    "label = scaler_y.fit_transform(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12791765151515147"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we load our regressor, execute k-Fold, train and test our algorithm\n",
    "\n",
    "# KNN\n",
    "from sklearn import neighbors\n",
    "\n",
    "# Applies StratifiedKFold with k = 5 and repeats process 33 times for statistical robustness\n",
    "resultados33 = []\n",
    "\n",
    "for i in range(33):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = i)\n",
    "    resultados1 = []\n",
    "    for n_train, n_test in kfold.split(previsores, np.zeros(shape=(previsores.shape[0], 1))):\n",
    "        # Train the KNN regressor \n",
    "        regressor = neighbors.KNeighborsRegressor(n_neighbors = 4)\n",
    "        # Fitting and prediction \n",
    "        regressor.fit(previsores[n_train], label[n_train].ravel())\n",
    "        previsoes = regressor.predict(previsores[n_test])\n",
    "        # Applying the inverse scale\n",
    "        valores_previsao = np.asarray(previsoes).reshape(-1,1)\n",
    "        valores_previsao = scaler_y.inverse_transform(valores_previsao) \n",
    "        y_teste = label[n_test].tolist()\n",
    "        y_teste = scaler_y.inverse_transform(label[n_test]) \n",
    "        # Calculating the mean absolute error (MAE)\n",
    "        mae = mean_absolute_error(y_teste, valores_previsao)   \n",
    "        resultados1.append(mae)\n",
    "    # Appending all the steps\n",
    "    resultados1 = np.asarray(resultados1)\n",
    "    media = resultados1.mean()\n",
    "    resultados33 = np.append(resultados33, media)\n",
    "# Final results\n",
    "resultados33 = np.asarray(resultados33)\n",
    "\n",
    "# Enable to obtain processing time\n",
    "# end = time.time()\n",
    "# tempo = end - start\n",
    "\n",
    "# Enable to display classification mean and standard deviation\n",
    "resultados33.mean()\n",
    "# resultados33.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.27016565398503"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we load our regressor, execute k-Fold, train and test our algorithm\n",
    "\n",
    "# MLP\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "# Applies StratifiedKFold with k = 5 and repeats process 33 times for statistical robustness\n",
    "resultados33 = []\n",
    "\n",
    "for i in range(33):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = i)\n",
    "    resultados1 = []\n",
    "    for n_train, n_test in kfold.split(previsores, np.zeros(shape=(previsores.shape[0], 1))):\n",
    "        # Train the MLP regressor \n",
    "        regressor = MLPRegressor(activation = 'tanh',\n",
    "                                 hidden_layer_sizes = 22,\n",
    "                                 learning_rate = 'invscaling',\n",
    "                                 learning_rate_init = 0.03026389988096674,\n",
    "                                 max_iter = 5700,\n",
    "                                 solver = 'lbfgs')\n",
    "        # Fitting and prediction \n",
    "        regressor.fit(previsores[n_train], label[n_train].ravel())\n",
    "        previsoes = regressor.predict(previsores[n_test])\n",
    "        # Applying the inverse scale\n",
    "        valores_previsao = np.asarray(previsoes).reshape(-1,1)\n",
    "        valores_previsao = scaler_y.inverse_transform(valores_previsao) \n",
    "        y_teste = label[n_test].tolist()\n",
    "        y_teste = scaler_y.inverse_transform(label[n_test]) \n",
    "        # Calculating the mean absolute error (MAE)\n",
    "        mae = mean_absolute_error(y_teste, valores_previsao)   \n",
    "        resultados1.append(mae)\n",
    "    # Appending all the steps\n",
    "    resultados1 = np.asarray(resultados1)\n",
    "    media = resultados1.mean()\n",
    "    resultados33 = np.append(resultados33, media)\n",
    "# Final results\n",
    "resultados33 = np.asarray(resultados33)\n",
    "\n",
    "# Enable to obtain processing time\n",
    "# end = time.time()\n",
    "# tempo = end - start\n",
    "\n",
    "# Enable to display classification mean and standard deviation\n",
    "resultados33.mean()\n",
    "# resultados33.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12038365699826047"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we load our regressor, execute k-Fold, train and test our algorithm\n",
    "\n",
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Applies StratifiedKFold with k = 5 and repeats process 33 times for statistical robustness\n",
    "resultados33 = []\n",
    "\n",
    "for i in range(33):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = i)\n",
    "    resultados1 = []\n",
    "    for n_train, n_test in kfold.split(previsores, np.zeros(shape=(previsores.shape[0], 1))):\n",
    "        # Train the Random Forest regressor \n",
    "        regressor = RandomForestRegressor(criterion = 'mse',\n",
    "                                          max_depth = 9,\n",
    "                                          max_features = 0.4,\n",
    "                                          n_estimators = 106) \n",
    "        # Fitting and prediction \n",
    "        regressor.fit(previsores[n_train], label[n_train].ravel())\n",
    "        previsoes = regressor.predict(previsores[n_test])\n",
    "        # Applying the inverse scale\n",
    "        valores_previsao = np.asarray(previsoes).reshape(-1,1)\n",
    "        valores_previsao = scaler_y.inverse_transform(valores_previsao) \n",
    "        y_teste = label[n_test].tolist()\n",
    "        y_teste = scaler_y.inverse_transform(label[n_test]) \n",
    "        # Calculating the mean absolute error (MAE)\n",
    "        mae = mean_absolute_error(y_teste, valores_previsao)   \n",
    "        resultados1.append(mae)\n",
    "    # Appending all the steps\n",
    "    resultados1 = np.asarray(resultados1)\n",
    "    media = resultados1.mean()\n",
    "    resultados33 = np.append(resultados33, media)\n",
    "# Final results\n",
    "resultados33 = np.asarray(resultados33)\n",
    "\n",
    "# Enable to obtain processing time\n",
    "# end = time.time()\n",
    "# tempo = end - start\n",
    "\n",
    "# Enable to display classification mean and standard deviation\n",
    "resultados33.mean()\n",
    "# resultados33.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12507082676496703"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we load our regressor, execute k-Fold, train and test our algorithm\n",
    "\n",
    "# Gradient Boosting Machine (GBM)\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Applies StratifiedKFold with k = 5 and repeats process 33 times for statistical robustness\n",
    "resultados33 = []\n",
    "\n",
    "for i in range(33):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = i)\n",
    "    resultados1 = []\n",
    "    for n_train, n_test in kfold.split(previsores, np.zeros(shape=(previsores.shape[0], 1))):\n",
    "        # Train the GBM regressor \n",
    "        regressor = GradientBoostingRegressor(criterion = 'mse',\n",
    "                                              learning_rate = 0.06856362171992,\n",
    "                                              max_depth = 6,\n",
    "                                              max_features = 0.5,\n",
    "                                              n_estimators = 84,\n",
    "                                              subsample = 0.8)\n",
    "        # Fitting and prediction \n",
    "        regressor.fit(previsores[n_train], label[n_train].ravel())\n",
    "        previsoes = regressor.predict(previsores[n_test])\n",
    "        # Applying the inverse scale\n",
    "        valores_previsao = np.asarray(previsoes).reshape(-1,1)\n",
    "        valores_previsao = scaler_y.inverse_transform(valores_previsao) \n",
    "        y_teste = label[n_test].tolist()\n",
    "        y_teste = scaler_y.inverse_transform(label[n_test]) \n",
    "        # Calculating the mean absolute error (MAE)\n",
    "        mae = mean_absolute_error(y_teste, valores_previsao)   \n",
    "        resultados1.append(mae)\n",
    "    # Appending all the steps\n",
    "    resultados1 = np.asarray(resultados1)\n",
    "    media = resultados1.mean()\n",
    "    resultados33 = np.append(resultados33, media)\n",
    "# Final results\n",
    "resultados33 = np.asarray(resultados33)\n",
    "\n",
    "# Enable to obtain processing time\n",
    "# end = time.time()\n",
    "# tempo = end - start\n",
    "\n",
    "# Enable to display classification mean and standard deviation\n",
    "resultados33.mean()\n",
    "# resultados33.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.11394650994318796"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we load our regressor, execute k-Fold, train and test our algorithm\n",
    "\n",
    "# LightGBM\n",
    "import lightgbm\n",
    "\n",
    "# Applies StratifiedKFold with k = 5 and repeats process 33 times for statistical robustness\n",
    "resultados33 = []\n",
    "\n",
    "for i in range(33):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = i)\n",
    "    resultados1 = []\n",
    "    for n_train, n_test in kfold.split(previsores, np.zeros(shape=(previsores.shape[0], 1))):\n",
    "        # Train the LightGBM regressor \n",
    "        regressor = lightgbm.LGBMRegressor(objective = 'regression_l1',\n",
    "                                           bagging_fraction = 0.8,\n",
    "                                           eval_metric = 'mae',\n",
    "                                           feature_fraction = 0.4,\n",
    "                                           learning_rate = 0.08165872333050837,\n",
    "                                           max_depth = 9,\n",
    "                                           n_estimators = 148)\n",
    "        # Fitting and prediction \n",
    "        regressor.fit(previsores[n_train], label[n_train].ravel())\n",
    "        previsoes = regressor.predict(previsores[n_test])\n",
    "        # Applying the inverse scale\n",
    "        valores_previsao = np.asarray(previsoes).reshape(-1,1)\n",
    "        valores_previsao = scaler_y.inverse_transform(valores_previsao) \n",
    "        y_teste = label[n_test].tolist()\n",
    "        y_teste = scaler_y.inverse_transform(label[n_test]) \n",
    "        # Calculating the mean absolute error (MAE)\n",
    "        mae = mean_absolute_error(y_teste, valores_previsao)   \n",
    "        resultados1.append(mae)\n",
    "    # Appending all the steps\n",
    "    resultados1 = np.asarray(resultados1)\n",
    "    media = resultados1.mean()\n",
    "    resultados33 = np.append(resultados33, media)\n",
    "# Final results\n",
    "resultados33 = np.asarray(resultados33)\n",
    "\n",
    "# Enable to obtain processing time\n",
    "# end = time.time()\n",
    "# tempo = end - start\n",
    "\n",
    "# Enable to display classification mean and standard deviation\n",
    "resultados33.mean()\n",
    "# resultados33.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12343192373472259"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we load our regressor, execute k-Fold, train and test our algorithm\n",
    "\n",
    "# XGBoost \n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Applies StratifiedKFold with k = 5 and repeats process 33 times for statistical robustness\n",
    "resultados33 = []\n",
    "\n",
    "for i in range(33):\n",
    "    kfold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = i)\n",
    "    resultados1 = []\n",
    "    for n_train, n_test in kfold.split(previsores, np.zeros(shape=(previsores.shape[0], 1))):\n",
    "        # Train the XGBoost regressor \n",
    "        regressor = xgb.XGBRegressor(colsample_bylevel = 0.7,\n",
    "                                     colsample_bynode = 0.8,\n",
    "                                     colsample_bytree = 0.5,\n",
    "                                     eval_metric = 'mae',\n",
    "                                     learning_rate = 0.04638617378157029,\n",
    "                                     max_depth = 6,\n",
    "                                     n_estimators = 174,\n",
    "                                     objective = 'reg:squarederror')\n",
    "        # Fitting and prediction \n",
    "        regressor.fit(previsores[n_train], label[n_train].ravel())\n",
    "        previsoes = regressor.predict(previsores[n_test])\n",
    "        # Applying the inverse scale\n",
    "        valores_previsao = np.asarray(previsoes).reshape(-1,1)\n",
    "        valores_previsao = scaler_y.inverse_transform(valores_previsao) \n",
    "        y_teste = label[n_test].tolist()\n",
    "        y_teste = scaler_y.inverse_transform(label[n_test]) \n",
    "        # Calculating the mean absolute error (MAE)\n",
    "        mae = mean_absolute_error(y_teste, valores_previsao)   \n",
    "        resultados1.append(mae)\n",
    "    # Appending all the steps\n",
    "    resultados1 = np.asarray(resultados1)\n",
    "    media = resultados1.mean()\n",
    "    resultados33 = np.append(resultados33, media)\n",
    "# Final results\n",
    "resultados33 = np.asarray(resultados33)\n",
    "\n",
    "# Enable to obtain processing time\n",
    "# end = time.time()\n",
    "# tempo = end - start\n",
    "\n",
    "# Enable to display classification mean and standard deviation\n",
    "resultados33.mean()\n",
    "# resultados33.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
